{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACXad-72RqGW",
    "outputId": "da5daf45-120b-4f88-97ca-9b11eff884ab"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card = pd.read_csv('creditcard.csv')\n",
    "X = credit_card.drop(columns='Class', axis=1)\n",
    "X['logAmount'] =  np.log(X['Amount'] + 1.0)\n",
    "X = X.drop(columns=['Amount', 'Time'], axis=1)\n",
    "y = credit_card.Class.values\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# y_train, y_test = np.array([-1 if y==0 else 1 for y in y_train]), np.array([-1 if y==0 else 1 for y in y_test])\n",
    "y_train, y_test = y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "y_train, y_test = y_train.astype(np.float32), y_test.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogModel():\n",
    "    def __init__(self, optimizer=None, learning_rate=0.01):\n",
    "        super(LogModel, self).__init__()\n",
    "        if optimizer:\n",
    "            self.optimizer = optimizer(learning_rate)\n",
    "        else:\n",
    "            self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, decay=0.01)\n",
    "\n",
    "    def loss(self, pred, true):\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        return loss(pred, true)\n",
    "\n",
    "    def accuracy(self, pred, true):\n",
    "        check_prediction = tf.equal(tf.round(pred), true)\n",
    "        return tf.reduce_mean(tf.cast(check_prediction, tf.float32)) * 100\n",
    "\n",
    "    def predict(self, x):\n",
    "        return tf.nn.sigmoid(tf.matmul(x, self.w) + self.b)\n",
    "        \n",
    "    def fit(self, x, y, n_epochs, batch_size, validation_data=None):\n",
    "        self.w = tf.Variable(tf.random.truncated_normal([x.shape[1], 1]), name=\"weight\", trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([1]), name='bias', trainable=True)     \n",
    "\n",
    "        train_data=tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy= []\n",
    "        if validation_data:\n",
    "            self.valid_accuracy = []\n",
    "            self.valid_loss = []\n",
    "        for step, (batch_x, batch_y) in enumerate(train_data.take(n_epochs), 1):\n",
    "            # Run the optimization to update W and b values.\n",
    "            with tf.GradientTape() as g:\n",
    "                pred = tf.nn.sigmoid(tf.matmul(batch_x, self.w) + self.b)\n",
    "                loss = self.loss(pred, batch_y)\n",
    "                self.train_loss.append(loss)\n",
    "                self.train_accuracy.append(self.accuracy(pred, batch_y))\n",
    "            # Compute gradients.\n",
    "            gradients = g.gradient(loss, [self.w, self.b])\n",
    "            self.optimizer.apply_gradients(zip(gradients, [self.w, self.b]))\n",
    "            if validation_data:\n",
    "                x_val, y_val = validation_data\n",
    "                pred_val = self.predict(x_val)\n",
    "                self.valid_loss.append(self.loss(pred_val, y_val))\n",
    "                self.valid_accuracy.append(self.accuracy(pred_val, y_val))\n",
    "                \n",
    "                if step % 50 == 0:\n",
    "                    print(\"Iteration: %i, loss: %.2f, accuracy: %.2f, loss_val: %.2f, accuracy_val: %.2f\" % (step, \n",
    "                    self.train_loss[step-1], self.train_accuracy[step-1], self.valid_loss[step-1], self.valid_accuracy[step-1]))\n",
    "            else:\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Iteration: %i, loss: %.2f, accuracy: %.2f\" % (step, self.train_loss[step-1], self.train_accuracy[step-1]))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50, loss: 3.23, accuracy: 82.80\n",
      "Iteration: 100, loss: 1.23, accuracy: 95.60\n",
      "Iteration: 150, loss: 0.63, accuracy: 97.60\n",
      "Iteration: 200, loss: 0.71, accuracy: 96.40\n",
      "Iteration: 250, loss: 0.55, accuracy: 97.20\n",
      "Iteration: 300, loss: 0.45, accuracy: 97.60\n",
      "Iteration: 350, loss: 0.59, accuracy: 96.60\n",
      "Iteration: 400, loss: 0.58, accuracy: 96.40\n",
      "Iteration: 450, loss: 0.44, accuracy: 97.60\n",
      "Iteration: 500, loss: 0.23, accuracy: 99.00\n",
      "Iteration: 550, loss: 0.11, accuracy: 99.60\n",
      "Iteration: 600, loss: 0.04, accuracy: 100.00\n",
      "Iteration: 650, loss: 0.07, accuracy: 99.80\n",
      "Iteration: 700, loss: 0.03, accuracy: 100.00\n",
      "Iteration: 750, loss: 0.03, accuracy: 100.00\n",
      "Iteration: 800, loss: 0.05, accuracy: 99.80\n",
      "Iteration: 850, loss: 0.05, accuracy: 99.80\n",
      "Iteration: 900, loss: 0.05, accuracy: 99.80\n",
      "Iteration: 950, loss: 0.02, accuracy: 100.00\n",
      "Iteration: 1000, loss: 0.02, accuracy: 100.00\n",
      "Iteration: 1050, loss: 0.05, accuracy: 99.80\n",
      "Iteration: 1100, loss: 0.04, accuracy: 99.80\n",
      "Iteration: 1150, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1200, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1250, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1300, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1350, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1400, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1450, loss: 0.04, accuracy: 99.80\n",
      "Iteration: 1500, loss: 0.04, accuracy: 99.80\n",
      "Iteration: 1550, loss: 0.04, accuracy: 99.80\n",
      "Iteration: 1600, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1650, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1700, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1750, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1800, loss: 0.04, accuracy: 99.80\n",
      "Iteration: 1850, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1900, loss: 0.01, accuracy: 100.00\n",
      "Iteration: 1950, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2000, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2050, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2100, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2150, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2200, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 2250, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2300, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 2350, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2400, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2450, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2500, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 2550, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2600, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2650, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2700, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2750, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2800, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2850, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2900, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 2950, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3000, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3050, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3100, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3150, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3200, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3250, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3300, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3350, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3400, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3450, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3500, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3550, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3600, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3650, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3700, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3750, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3800, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3850, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 3900, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 3950, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4000, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 4050, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4100, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4150, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4200, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4250, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4300, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4350, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4400, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 4450, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 4500, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4550, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4600, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4650, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4700, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4750, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4800, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4850, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4900, loss: 0.00, accuracy: 100.00\n",
      "Iteration: 4950, loss: 0.03, accuracy: 99.80\n",
      "Iteration: 5000, loss: 0.00, accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "lr = LogModel(optimizer=tf.keras.optimizers.Adam, learning_rate=0.03)\n",
    "lr.fit(X_train, y_train, n_epochs=5000, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmvbW4TiRqGi",
    "outputId": "3fc2145b-e184-4940-eaaa-9467190e9a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[71059    30]\n",
      " [   22    91]]\n",
      "Test accuracy: 99.9270 %\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = np.round(lr.predict(X_test))\n",
    "# y_test_hat_probs = lr.predict_proba(X_test)[:,1]\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)*100\n",
    "# test_auc_roc = roc_auc_score(y_test, y_test_hat_probs)*100\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "print('Test accuracy: %.4f %%' % test_accuracy)\n",
    "# print('Test AUC: %.4f %%' % test_auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBhp7O5JRqGj",
    "outputId": "96d8460c-9718-4459-a6d4-78f42f12301f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0   0.999690  0.999578  0.999634     71089\n",
      "         1.0   0.752066  0.805310  0.777778       113\n",
      "\n",
      "    accuracy                       0.999270     71202\n",
      "   macro avg   0.875878  0.902444  0.888706     71202\n",
      "weighted avg   0.999298  0.999270  0.999282     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_hat, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Question_1-SVM-Copy2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
