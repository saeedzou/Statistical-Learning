{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix , f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card = pd.read_csv('creditcard.csv')\n",
    "X = credit_card.drop(columns='Class', axis=1)\n",
    "y = credit_card.Class.values\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "y_train, y_test = np.array([-1 if y==0 else 1 for y in y_train]), np.array([-1 if y==0 else 1 for y in y_test])\n",
    "y_train, y_test = y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "y_train, y_test = y_train.astype(np.float32), y_test.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test = scaler.transform(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm():\n",
    "    def __init__(self):\n",
    "        super(svm, self).__init__()\n",
    "    \n",
    "    def predict(self, x, logits=False):\n",
    "        if logits:\n",
    "            return tf.subtract(tf.matmul(x, self.w), self.b)\n",
    "        else:\n",
    "            return tf.sign(tf.subtract(tf.matmul(x, self.w), self.b))\n",
    "    \n",
    "    def loss(self, pred, true):\n",
    "        classification_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(pred, true))))\n",
    "        loss = tf.add(classification_term, tf.multiply(self.alpha, tf.reduce_sum(tf.square(self.w))))\n",
    "        return loss\n",
    "    def accuracy(self, pred, true):\n",
    "        check_prediction = tf.equal(tf.sign(pred), true)\n",
    "        accuracy_op = tf.reduce_mean(tf.cast(check_prediction, tf.float32)) * 100\n",
    "        return accuracy_op\n",
    "    \n",
    "    def fit(self, x, y, n_epochs, batch_size, validation_data=None, alpha=0.1, learning_rate=0.01):\n",
    "        print(f\"epochs={n_epochs}, batch size={batch_size}, learning rate={learning_rate}, alpha={alpha}\")\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "        self.alpha = tf.constant([alpha])\n",
    "        self.w = tf.Variable(tf.random.truncated_normal([x.shape[1], 1]), name=\"weight\", trainable=True)\n",
    "        self.b = tf.Variable(tf.zeros([1]), name='bias', trainable=True)     \n",
    "\n",
    "        train_data=tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy= []\n",
    "        if validation_data:\n",
    "            self.valid_accuracy = []\n",
    "            self.valid_loss = []\n",
    "        for step, (batch_x, batch_y) in enumerate(train_data.take(n_epochs), 1):\n",
    "            # Run the optimization to update W and b values.\n",
    "            with tf.GradientTape() as g:\n",
    "                pred = tf.subtract(tf.matmul(batch_x, self.w), self.b)\n",
    "                loss = self.loss(pred, batch_y)\n",
    "                self.train_loss.append(loss)\n",
    "                self.train_accuracy.append(self.accuracy(pred, batch_y))\n",
    "            # Compute gradients.\n",
    "            gradients = g.gradient(loss, [self.w, self.b])\n",
    "            self.optimizer.apply_gradients(zip(gradients, [self.w, self.b]))\n",
    "            if validation_data:\n",
    "                x_val, y_val = validation_data\n",
    "                pred_val = self.predict(x_val)\n",
    "                self.valid_loss.append(self.loss(pred_val, y_val))\n",
    "                self.valid_accuracy.append(self.accuracy(pred_val, y_val))\n",
    "                \n",
    "                if step % 50 == 0:\n",
    "                    print(\"Iteration: %i, loss: %.2f, accuracy: %.2f, loss_val: %.2f, accuracy_val: %.2f\" % (step, \n",
    "                    self.train_loss[step-1], self.train_accuracy[step-1], self.valid_loss[step-1], self.valid_accuracy[step-1]))\n",
    "            else:\n",
    "                if step % 50 == 0:\n",
    "                    print(\"Iteration: %i, loss: %.4f, accuracy: %.2f\" % (step, self.train_loss[step-1], self.train_accuracy[step-1]))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs=10000, batch size=500, learning rate=0.001, alpha=0.003\n",
      "Iteration: 50, loss: 2.40, accuracy: 49.20, loss_val: 1.06, accuracy_val: 50.75\n",
      "Iteration: 100, loss: 2.29, accuracy: 48.60, loss_val: 1.04, accuracy_val: 51.44\n",
      "Iteration: 150, loss: 1.79, accuracy: 55.00, loss_val: 1.02, accuracy_val: 52.14\n",
      "Iteration: 200, loss: 2.06, accuracy: 52.00, loss_val: 1.00, accuracy_val: 52.80\n",
      "Iteration: 250, loss: 1.71, accuracy: 53.20, loss_val: 0.98, accuracy_val: 53.69\n",
      "Iteration: 300, loss: 1.62, accuracy: 57.20, loss_val: 0.96, accuracy_val: 54.70\n",
      "Iteration: 350, loss: 1.53, accuracy: 58.80, loss_val: 0.93, accuracy_val: 55.69\n",
      "Iteration: 400, loss: 1.45, accuracy: 56.60, loss_val: 0.90, accuracy_val: 56.89\n",
      "Iteration: 450, loss: 1.21, accuracy: 64.60, loss_val: 0.87, accuracy_val: 58.26\n",
      "Iteration: 500, loss: 1.35, accuracy: 59.60, loss_val: 0.84, accuracy_val: 59.67\n",
      "Iteration: 550, loss: 1.29, accuracy: 60.60, loss_val: 0.81, accuracy_val: 61.26\n",
      "Iteration: 600, loss: 1.37, accuracy: 60.80, loss_val: 0.77, accuracy_val: 63.05\n",
      "Iteration: 650, loss: 1.00, accuracy: 68.40, loss_val: 0.73, accuracy_val: 64.91\n",
      "Iteration: 700, loss: 1.05, accuracy: 65.80, loss_val: 0.68, accuracy_val: 67.13\n",
      "Iteration: 750, loss: 0.88, accuracy: 69.00, loss_val: 0.63, accuracy_val: 69.59\n",
      "Iteration: 800, loss: 1.07, accuracy: 72.00, loss_val: 0.58, accuracy_val: 72.02\n",
      "Iteration: 850, loss: 0.77, accuracy: 73.20, loss_val: 0.52, accuracy_val: 74.82\n",
      "Iteration: 900, loss: 0.55, accuracy: 80.80, loss_val: 0.46, accuracy_val: 77.85\n",
      "Iteration: 950, loss: 0.76, accuracy: 76.20, loss_val: 0.39, accuracy_val: 81.03\n",
      "Iteration: 1000, loss: 0.50, accuracy: 85.20, loss_val: 0.33, accuracy_val: 84.00\n",
      "Iteration: 1050, loss: 0.42, accuracy: 86.40, loss_val: 0.28, accuracy_val: 86.72\n",
      "Iteration: 1100, loss: 0.40, accuracy: 90.20, loss_val: 0.22, accuracy_val: 89.36\n",
      "Iteration: 1150, loss: 0.31, accuracy: 92.20, loss_val: 0.18, accuracy_val: 91.36\n",
      "Iteration: 1200, loss: 0.28, accuracy: 94.00, loss_val: 0.14, accuracy_val: 93.27\n",
      "Iteration: 1250, loss: 0.21, accuracy: 96.20, loss_val: 0.11, accuracy_val: 94.76\n",
      "Iteration: 1300, loss: 0.25, accuracy: 93.80, loss_val: 0.09, accuracy_val: 95.88\n",
      "Iteration: 1350, loss: 0.09, accuracy: 98.00, loss_val: 0.07, accuracy_val: 96.80\n",
      "Iteration: 1400, loss: 0.08, accuracy: 99.00, loss_val: 0.05, accuracy_val: 97.58\n",
      "Iteration: 1450, loss: 0.11, accuracy: 97.60, loss_val: 0.04, accuracy_val: 98.22\n",
      "Iteration: 1500, loss: 0.07, accuracy: 98.20, loss_val: 0.03, accuracy_val: 98.78\n",
      "Iteration: 1550, loss: 0.03, accuracy: 99.40, loss_val: 0.02, accuracy_val: 99.23\n",
      "Iteration: 1600, loss: 0.02, accuracy: 100.00, loss_val: 0.01, accuracy_val: 99.53\n",
      "Iteration: 1650, loss: 0.01, accuracy: 99.60, loss_val: 0.01, accuracy_val: 99.68\n",
      "Iteration: 1700, loss: 0.01, accuracy: 99.60, loss_val: 0.01, accuracy_val: 99.76\n",
      "Iteration: 1750, loss: 0.02, accuracy: 99.60, loss_val: 0.01, accuracy_val: 99.80\n",
      "Iteration: 1800, loss: 0.01, accuracy: 99.80, loss_val: 0.01, accuracy_val: 99.85\n",
      "Iteration: 1850, loss: 0.01, accuracy: 99.80, loss_val: 0.01, accuracy_val: 99.87\n",
      "Iteration: 1900, loss: 0.01, accuracy: 99.80, loss_val: 0.01, accuracy_val: 99.90\n",
      "Iteration: 1950, loss: 0.00, accuracy: 100.00, loss_val: 0.01, accuracy_val: 99.91\n",
      "Iteration: 2000, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.91\n",
      "Iteration: 2050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2100, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.91\n",
      "Iteration: 2150, loss: 0.01, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2200, loss: 0.02, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.91\n",
      "Iteration: 2250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2300, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2350, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2500, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2650, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.92\n",
      "Iteration: 2750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 2800, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 2850, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 2900, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 2950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3100, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3150, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3350, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 3500, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3550, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3800, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 3850, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 3900, loss: 0.01, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 3950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4100, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4150, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4350, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4500, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4750, loss: 0.01, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4800, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4850, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4900, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 4950, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5050, loss: 0.02, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5100, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5150, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5250, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5350, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5400, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5500, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5800, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5850, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5900, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 5950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6100, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6150, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6350, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6500, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6800, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6850, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6900, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 6950, loss: 0.02, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7000, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7100, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7150, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7350, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7500, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7600, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7800, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7850, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7900, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 7950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8000, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8100, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8150, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8200, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8300, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8350, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8450, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8500, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8550, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8600, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8650, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8700, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8800, loss: 0.01, accuracy: 99.40, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8850, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8900, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 8950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9050, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9100, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9150, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9200, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9250, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9300, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.93\n",
      "Iteration: 9350, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9400, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9450, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9500, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9550, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9600, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9650, loss: 0.01, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9700, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9750, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9800, loss: 0.01, accuracy: 99.60, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9850, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9900, loss: 0.00, accuracy: 99.80, loss_val: 0.00, accuracy_val: 99.94\n",
      "Iteration: 9950, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000, loss: 0.00, accuracy: 100.00, loss_val: 0.00, accuracy_val: 99.94\n"
     ]
    }
   ],
   "source": [
    "model = svm()\n",
    "model.fit(X_train, y_train, 10000, 500, learning_rate=0.001, alpha=0.003, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[213191     35]\n",
      " [    90    289]]\n",
      "Training accuracy: 99.9415 %\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = model.predict(X_train)\n",
    "# y_train_hat_probs = lr.predict_proba(X_train)[:,1]\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)*100\n",
    "# train_auc_roc = roc_auc_score(y_train, y_train_hat_probs)*100\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat))\n",
    "print('Training accuracy: %.4f %%' % train_accuracy)\n",
    "# print('Training AUC: %.4f %%' % train_auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[71072    17]\n",
      " [   28    85]]\n",
      "Test accuracy: 99.9368 %\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "# y_test_hat_probs = lr.predict_proba(X_test)[:,1]\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)*100\n",
    "# test_auc_roc = roc_auc_score(y_test, y_test_hat_probs)*100\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "print('Test accuracy: %.4f %%' % test_accuracy)\n",
    "# print('Test AUC: %.4f %%' % test_auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0   0.999606  0.999761  0.999684     71089\n",
      "         1.0   0.833333  0.752212  0.790698       113\n",
      "\n",
      "    accuracy                       0.999368     71202\n",
      "   macro avg   0.916470  0.875987  0.895191     71202\n",
      "weighted avg   0.999342  0.999368  0.999352     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_hat, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(lr.train_accuracy, label='train_accuracy')\n",
    "plt.plot(lr.valid_accuracy, label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(lr.train_loss, label='train_loss')\n",
    "plt.plot(lr.valid_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
